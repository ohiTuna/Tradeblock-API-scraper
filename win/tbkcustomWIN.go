package main

import (
	"bytes"
	"encoding/csv"
	"encoding/json"
	//	"errors"
	"fmt"
	"log"
	"net/http"
	"os"
	"strconv"
	"time"
	//	"net/url"
	"bufio"
)

// One fee in the JSON response
type AutoGenerated struct {
	Data []Stat `json:"data"`
}

type Stat struct {
	Timestamp int //`json:"num_int"`
	FeeJ      json.Number `json:"num_float"`
}
//JSON unmarshaller, do not change
func (s *Stat) UnmarshalJSON(data []byte) error {
	var tmp []int
	if s.Timestamp < 6000 {
		json.Unmarshal(data, &tmp)
	}
	s.Timestamp = tmp[0]

	var blk []json.Number
	if err := json.Unmarshal(data, &blk); err != nil {
		return err
	}
	s.FeeJ = blk[1]

	return nil
}

func main() {

	var inType string
	var inInterval string
	var inDate string
	var inRuns int
start:
	fmt.Println("Enter 1, 2, 3, or 4 for data type: \n" +
		"1 - txsize_new - sum size of all tx for selected interval \n" +
		"2 - txfee_new - sum of all tx fees for interval (in satoshis) \n" +
		"3 - txes_new - total number of txs for interval \n" +
		"4 - blocks_new total blocks mined for interval \n" +
		"9 - exit program")
	scn := bufio.NewScanner(os.Stdin)
	scn.Scan()
	line := scn.Text()
	if line == "1" {
		inType = "txsize_new"
	} else if line == "2" {
		inType = "txfee_new"
	} else if line == "3" {
		inType = "txes_new"
	} else if line == "4" {
		inType = "blocks_new"
	} else if line == "9" {
		os.Exit(0)
	}
	sleeper(800)
	sleeper(800)
	fmt.Scanf("%v", &inDate)
	fmt.Println("\nEnter interval to query: 1h, 2h, 6h, 1d \n" +
		"interval must be entered as '1h' '2h' '6h' or '1d' NO OTHER intervals are permitted")
	fmt.Scanf("%s", &inInterval)

	fmt.Printf("Enter ending date value to pull: 86400=24hours")
	t := time.Now()
	utime := t.Unix()
//	fmt.Println("Current time is: ", t.Unix())
	sleeper(800)
//	fmt.Println(" if", utime, "is entered with interval at 6h then 1000 records will " +
//		"be retrieved starting at", utime-21600000, "(which is ",time.Unix(utime - 21600000, 0), ")")
	//	var currentTimestamp int
//	var inDatecheck int64


//	---WORK IN PROGRESS for inDate checker/user confirm
/*	for x:=0;x>=1;{
		if inInterval == "1h" {
			fmt.Println("Records will be each hour from")
			fmt.Println(time.Unix(inDatecheck-3600000, 0), "to", time.Unix(inDatecheck, 0))
			fmt.Println("Confirm? type y or n.")
			var chk string
			fmt.Scanf("%s", &chk)
			if chk == "n"{

			}
		}
	}
*/
//	---END
	fmt.Println("\nNumber of instances back to run?")
	sleeper(100)
	fmt.Println(" '3' with 1h interval and ending date at ", utime, " will retrieve the 3000 \n" +
		" hour values prior to ", utime)
	var instChecker int
	fmt.Scanf("%v", &instChecker)
	for ; instChecker > 10; {
		fmt.Println("Please enter integer between 1-10")
		fmt.Scanf("%v", &instChecker)
	}
	inRuns = instChecker
	inRuns--

	sleeper(500)

	//creation of CSV file
	ruffer := filenamer(inType, inInterval)
	xx := ruffer.String()
	Filecsv, err := os.Create(xx)
	fmt.Println("csv okay")
	if err != nil {
		fmt.Println("Cannot create")
	}
	defer Filecsv.Close()

	currentTimestamp, err := strconv.Atoi(inDate)
	if err != nil {
		log.Fatalf("date conversion to int failed", err)
	}
	urls := make([]string, 0)

	//creates URLS and writes different URLs as slices to 'urls'
	fmt.Println("making URL slices...")
	for i := 0; i <= inRuns; i++ {
		lurl := fmt.Sprintf("https://tradeblock.com/api/blockchain/statistics/%s/%s/%d", inType,
			inInterval, currentTimestamp)
		urls = append(urls, lurl)

		if inInterval == "1h" {
			currentTimestamp -= 3600000
		} else if inInterval == "2h" {
			currentTimestamp -= 7200000
		} else if inInterval == "6h" {
			currentTimestamp -= 21600000
		} else if inInterval == "1d" {
			currentTimestamp -= 86400000
		}
	}


	//carries out execution of decoder and reader/writer
	dataset := make([]Stat, 0, len(urls)*1)
	fmt.Println("dataset created!")
	for _, lurl := range urls {
		Currentdat := reader(inRuns, lurl)
		dataset = append(dataset, Currentdat.Data...)
		fmt.Println("appending dataset...")
	}
	fmt.Println("trying write...")
	writes(dataset, Filecsv)
	fmt.Println("write done! \n\n\n")
	time.Sleep(1500 * time.Millisecond)
	goto start

}

//decodes retrieved JSON data for each URL
func reader(inRuns int, urls ...string) (Currentdat AutoGenerated) {

	i := 0
	response, err := http.Get(urls[i])
	if err != nil {
		log.Fatalf("failed to get JSON data: %v", err)
	}
	//	defer response.Body.Close()
	dec := json.NewDecoder(response.Body)
	dec.UseNumber()
	Currentdat = AutoGenerated{}
	err = dec.Decode(&Currentdat)
	if err != nil {
		log.Fatalf("Failed to decode the JSON body: %v", err)
	}
	noter := string("interval set appended successfully!")
	fmt.Println(noter)

	return Currentdat

}

func sleeper(zzz time.Duration) {
	time.Sleep(zzz * time.Millisecond)

}
//takes decoded JSON and writes to CSV
func writes(dataset []Stat, Filecsv *os.File) {
	csvw := csv.NewWriter(Filecsv)
	fmt.Println("starting write...")
	var counter int = 1
	for _, Fee := range dataset {

		eqAa := "=(A"
		datecol2 := string("/24/60/60)+DATE(1970,1,1)")
		counter = counter + 1
		numFee := Fee.FeeJ.String()
		record := []string{strconv.Itoa(Fee.Timestamp), numFee, eqAa + strconv.Itoa(counter) + datecol2}

		csvw.Flush()
		csvw.Write(record)

		if err := csvw.Error(); err != nil {
			log.Fatalf("Could not write to CSV file:", err)
		}
	}
	return

}

//ugly timestamper for filename
func filenamer(inType, inInterval string) (bytes.Buffer) {

	hour, min := time.Now().Hour(), time.Now().Minute()
	_, month, day := time.Now().Date()
	h := strconv.Itoa(hour)
	n := strconv.Itoa(min)
	d := strconv.Itoa(day)
	m := strconv.Itoa(int(month))
	var zuffer bytes.Buffer
	zuffer.WriteString(inType)
	zuffer.WriteString(inInterval)
	zuffer.WriteString("-")
	zuffer.WriteString(m)
	zuffer.WriteString("-")
	zuffer.WriteString(d)
	zuffer.WriteString("at")
	zuffer.WriteString(h)
	zuffer.WriteString(n)
	zuffer.WriteString(".csv")

	return zuffer
}
